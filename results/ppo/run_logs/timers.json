{
    "name": "root",
    "gauges": {
        "Lizard.Policy.Entropy.mean": {
            "value": 2.357234477996826,
            "min": 2.1310484409332275,
            "max": 2.357234477996826,
            "count": 82
        },
        "Lizard.Policy.Entropy.sum": {
            "value": 70943.328125,
            "min": 19639.7421875,
            "max": 71870.765625,
            "count": 82
        },
        "Lizard.Step.mean": {
            "value": 10169996.0,
            "min": 7739912.0,
            "max": 10169996.0,
            "count": 82
        },
        "Lizard.Step.sum": {
            "value": 10169996.0,
            "min": 7739912.0,
            "max": 10169996.0,
            "count": 82
        },
        "Lizard.Policy.ExtrinsicValueEstimate.mean": {
            "value": -11.148385047912598,
            "min": -19.897537231445312,
            "max": -7.414607048034668,
            "count": 82
        },
        "Lizard.Policy.ExtrinsicValueEstimate.sum": {
            "value": -2909.728515625,
            "min": -5312.642578125,
            "max": -669.3268432617188,
            "count": 82
        },
        "Lizard.Policy.RndValueEstimate.mean": {
            "value": 0.003894707653671503,
            "min": -0.0048703402280807495,
            "max": 0.01744377426803112,
            "count": 82
        },
        "Lizard.Policy.RndValueEstimate.sum": {
            "value": 1.0165187120437622,
            "min": -1.2711588144302368,
            "max": 4.552824974060059,
            "count": 82
        },
        "Lizard.Environment.EpisodeLength.mean": {
            "value": 574.7884615384615,
            "min": 207.57142857142858,
            "max": 885.4285714285714,
            "count": 82
        },
        "Lizard.Environment.EpisodeLength.sum": {
            "value": 29889.0,
            "min": 1453.0,
            "max": 40248.0,
            "count": 82
        },
        "Lizard.Environment.CumulativeReward.mean": {
            "value": -76.36940532578872,
            "min": -93.5133940918105,
            "max": -55.267436941464744,
            "count": 82
        },
        "Lizard.Environment.CumulativeReward.sum": {
            "value": -3971.2090769410133,
            "min": -8890.77124774456,
            "max": -654.5937586426735,
            "count": 82
        },
        "Lizard.Policy.ExtrinsicReward.mean": {
            "value": -76.36940532578872,
            "min": -93.5133940918105,
            "max": -55.267436941464744,
            "count": 82
        },
        "Lizard.Policy.ExtrinsicReward.sum": {
            "value": -3971.2090769410133,
            "min": -8890.77124774456,
            "max": -654.5937586426735,
            "count": 82
        },
        "Lizard.Policy.RndReward.mean": {
            "value": 0.001868835890403576,
            "min": 0.0005868160068140631,
            "max": 0.0026667350426214397,
            "count": 82
        },
        "Lizard.Policy.RndReward.sum": {
            "value": 0.09717946630098595,
            "min": 0.004107712047698442,
            "max": 0.133336752131072,
            "count": 82
        },
        "Lizard.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 82
        },
        "Lizard.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 82
        },
        "Lizard.Losses.PolicyLoss.mean": {
            "value": 0.024010978358758924,
            "min": 0.01875555699548891,
            "max": 0.02957195604135955,
            "count": 81
        },
        "Lizard.Losses.PolicyLoss.sum": {
            "value": 0.07203293507627677,
            "min": 0.04117401936091483,
            "max": 0.08871586812407865,
            "count": 81
        },
        "Lizard.Losses.ValueLoss.mean": {
            "value": 33.15651037428114,
            "min": 15.724539136886595,
            "max": 64.56274380154079,
            "count": 81
        },
        "Lizard.Losses.ValueLoss.sum": {
            "value": 99.46953112284342,
            "min": 31.44907827377319,
            "max": 193.68823140462237,
            "count": 81
        },
        "Lizard.Policy.LearningRate.mean": {
            "value": 0.00029390479863173436,
            "min": 0.00029390479863173436,
            "max": 0.00029534589575136856,
            "count": 81
        },
        "Lizard.Policy.LearningRate.sum": {
            "value": 0.000881714395895203,
            "min": 0.000588174486941839,
            "max": 0.0008860376872541057,
            "count": 81
        },
        "Lizard.Policy.Epsilon.mean": {
            "value": 0.19796826553333335,
            "min": 0.19796826553333335,
            "max": 0.1984486314,
            "count": 81
        },
        "Lizard.Policy.Epsilon.sum": {
            "value": 0.5939047966000001,
            "min": 0.396058161,
            "max": 0.5953458942,
            "count": 81
        },
        "Lizard.Policy.Beta.mean": {
            "value": 0.009797029726780003,
            "min": 0.009797029726780003,
            "max": 0.009845018276860002,
            "count": 81
        },
        "Lizard.Policy.Beta.sum": {
            "value": 0.02939108918034001,
            "min": 0.019606210283900003,
            "max": 0.029535054830580006,
            "count": 81
        },
        "Lizard.Losses.RNDLoss.mean": {
            "value": 0.0003201457438990474,
            "min": 0.0002283895737491548,
            "max": 0.00042677437886595726,
            "count": 81
        },
        "Lizard.Losses.RNDLoss.sum": {
            "value": 0.0009604372316971421,
            "min": 0.0005001502577215433,
            "max": 0.0012803231365978718,
            "count": 81
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1717462678",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\RSheep\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn dqn_lizard.yaml --resume",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.3",
        "end_time_seconds": "1717464191"
    },
    "total": 1513.5542512999964,
    "count": 1,
    "self": 0.0036838999949395657,
    "children": {
        "run_training.setup": {
            "total": 0.05865710001671687,
            "count": 1,
            "self": 0.05865710001671687
        },
        "TrainerController.start_learning": {
            "total": 1513.4919102999847,
            "count": 1,
            "self": 1.4117041911231354,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.411842999979854,
                    "count": 1,
                    "self": 9.411842999979854
                },
                "TrainerController.advance": {
                    "total": 1502.5713454088545,
                    "count": 72409,
                    "self": 1.3650551059399731,
                    "children": {
                        "env_step": {
                            "total": 1002.4077194033307,
                            "count": 72409,
                            "self": 836.3986003974569,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 165.13793120742775,
                                    "count": 72409,
                                    "self": 5.221726896532346,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 159.9162043108954,
                                            "count": 68491,
                                            "self": 159.9162043108954
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.8711877984460443,
                                    "count": 72408,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1497.4844991081045,
                                            "count": 72408,
                                            "is_parallel": true,
                                            "self": 793.1142845074646,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00047450000420212746,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 6.910000229254365e-05,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0004054000019095838,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0004054000019095838
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 704.3697401006357,
                                                    "count": 72408,
                                                    "is_parallel": true,
                                                    "self": 15.118422316736542,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 46.47680938965641,
                                                            "count": 72408,
                                                            "is_parallel": true,
                                                            "self": 46.47680938965641
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 603.8327974922722,
                                                            "count": 72408,
                                                            "is_parallel": true,
                                                            "self": 603.8327974922722
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 38.94171090197051,
                                                            "count": 72408,
                                                            "is_parallel": true,
                                                            "self": 6.705340289161541,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 32.23637061280897,
                                                                    "count": 144816,
                                                                    "is_parallel": true,
                                                                    "self": 32.23637061280897
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 498.79857089958386,
                            "count": 72408,
                            "self": 2.6790997038478963,
                            "children": {
                                "process_trajectory": {
                                    "total": 201.3021202951204,
                                    "count": 72408,
                                    "self": 201.3021202951204
                                },
                                "_update_policy": {
                                    "total": 294.81735090061557,
                                    "count": 238,
                                    "self": 206.41597950318828,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 88.40137139742728,
                                            "count": 7146,
                                            "self": 88.40137139742728
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.400005754083395e-06,
                    "count": 1,
                    "self": 8.400005754083395e-06
                },
                "TrainerController._save_models": {
                    "total": 0.09700930002145469,
                    "count": 1,
                    "self": 0.01257600000826642,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.08443330001318827,
                            "count": 1,
                            "self": 0.08443330001318827
                        }
                    }
                }
            }
        }
    }
}